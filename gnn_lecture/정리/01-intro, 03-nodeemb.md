# Intro, NodeEmbedding


현실 세계의 모든 데이터들을 그리드, 시퀀스와 같은 구조로 표현할 수는 없습니다. 뿐만 아니라 이 데이터들은 표현의 한계를 갖기도 하고요. 하지만 그래프는 더 고차원적인 표현이 가능합니다. 따라서 기계학습 분야에서 인풋으로 그래프를 받는 것에 대한 연구가 많이 진행되어 왔습니다.

하지만 그래프는 분석하기가 어렵습니다. 따라서 그래프를 기계학습의 인풋으로 넣기 위해 적합한 형태로 바꾸어줄 필요가 있습니다. 이것이 NodeEmbedding 입니다. 

그래프는 그리드, 시퀀스보다 분석이 더 어렵습니다. 하지만 그만큼 더 많은 정보를 포함하고 있습니다. 노드 임베딩이라는 전처리 작업을 통해 그래프를 기계학습의 인풋으로 이용한다면 노드 간의 관계를 더 잘 이해할 수 있을 뿐 아니라 더 나아가 그래프 간의 관계도 학습할 수 있게 됩니다. 

노드 임베딩 작업은 임베딩된 공간 상의 두 노드 사이의 관계가 실제 그래프 상의 두 노드 사이의 관계를 최대한 비슷하게 근사하는 것을 목표로 합니다. 이를위해 단순 연결성 파악, 오버랩 기법들을 넘어 현재는 Random Walk 알고리즘을 이용합니다. 그리고 Node2vec 방식이 그 중 하나입니다. 

Random Walk의 기본 아이디어는 다음과 같습니다. 시작 노드 u로부터 이웃 노드들을 랜덤하게 방문, 특정 노드 v에 대한 방문 가능성을 예측합니다. 이 값이 클수록 두 노드는 높은 연결 관계가 있다고 판단될 수 있습니다. Random Walk 최적화 과정, 통계적 경사 하강법을 거칠 때 기존 그래프를 더 잘 표현할 수 있는 임베딩이 만들어진다고 이해했습니다. 자세한 과정은 건너 뛰었습니다. 

Node2Vec은 이웃 노드를 정의함에 있어 너비우선탐색과 깊이우선탐색을 이용합니다. 세부 알고리즘은 이해하지 못했습니다. 너비우선탐색은 local 이웃과 연관이 있고 깊이우선탐색은 global 이웃을 표현하는데 쓰이는 것 같습니다. 

남은 두 강좌가 GNN에 관한 것입니다. 01, 03 슬라이드에서 GNN이 언급된 부분은 shallow encoder 였습니다. shallow encoder가 embedding lookup이라 기술됐고 deeop encoder를 GNN으로 명시했습니다.
