>>SEED: 2020
##########################
[0;30;43mloading [./data/gowalla][0m
810128 interactions for training
217242 interactions for testing
gowalla Sparsity : 0.0008396216228570436
gowalla is ready to go
========================================CONFIG=====================================================
{'A_n_fold': 100,
 'A_split': False,
 'K': 3,
 'args': Namespace(K=3, a_fold=100, alpha=0.3, alpha1=0.25, alpha2=0.25, avg=0, beta=0.5, bpr_batch=4096, comment='gtn', dataset='gowalla', debug=True, decay=0.0001, dropout=0, epochs=101, gamma=1, gcn_model='GTN', gpu_id=0, incnorm_para=True, keepprob=0.6, lambda2=4.0, layer=3, load=0, lr=0.001, model='gtn', multicore=1, ogb=True, path='/home/hwiric/Internship/GTN-SIGIR2022/checkpoints_GTN', pretrain=0, prop_dropout=0.1, recdim=32, seed=2020, tensorboard=1, testbatch=100, topks='[20]'),
 'bigdata': False,
 'bpr_batch_size': 4096,
 'dataset': 'gowalla',
 'decay': 0.0001,
 'dropout': 0,
 'epochs': 101,
 'keep_prob': 0.6,
 'lambda2': 4.0,
 'latent_dim_rec': 32,
 'lr': 0.001,
 'multicore': 1,
 'pretrain': 0,
 'test_u_batch_size': 100}
cores for test: 24
comment: gtn
tensorboard: 1
LOAD: 0
Weight path: /home/hwiric/Internship/GTN-SIGIR2022/checkpoints_GTN
Test Topks: [20]
using bpr loss
==========================================END======================================================
##########################
[0;30;43muse NORMAL distribution initilizer[0m
loading adjacency matrix
generating adjacency matrix
Ïù∏Ï†ë ÌñâÎ†¨ ÏÉÅÌÉú ÌôïÏù∏
costing 68.95262575149536s, saved mat...
lgn is already to go(dropout:0)
##########################
[0;30;43m[TEST][0m

Testing EPOCH[1/101] | Results Top-k (pre, recall, ndcg): 0.00034, 0.00097, 0.00063

EPOCH[1/101] loss 18974.7465  18974.7465  0.0000 - |Sample:8.85|  |  02:37mins
EPOCH[2/101] loss 15154.5539  15154.5539  0.0000 - |Sample:8.93|  |  02:00mins
EPOCH[3/101] loss 13570.7611  13570.7611  0.0000 - |Sample:8.86|  |  02:01mins
EPOCH[4/101] loss 12520.1617  12520.1617  0.0000 - |Sample:8.63|  |  02:00mins
EPOCH[5/101] loss 11824.3206  11824.3206  0.0000 - |Sample:9.01|  |  02:01mins
EPOCH[6/101] loss 11170.5662  11170.5662  0.0000 - |Sample:8.90|  |  02:00mins
EPOCH[7/101] loss 10619.5283  10619.5283  0.0000 - |Sample:8.66|  |  02:00mins
EPOCH[8/101] loss 10150.4535  10150.4535  0.0000 - |Sample:8.90|  |  01:36mins
EPOCH[9/101] loss 9795.2408  9795.2408  0.0000 - |Sample:8.94|  |  02:01mins
EPOCH[10/101] loss 9382.0142  9382.0142  0.0000 - |Sample:8.91|  |  02:01mins
##########################
[0;30;43m[TEST][0m

Testing EPOCH[11/101] | Results Top-k (pre, recall, ndcg): 0.00066, 0.00231, 0.00164

EPOCH[11/101] loss 9155.3732  9155.3732  0.0001 - |Sample:8.72|  |  02:37mins
EPOCH[12/101] loss 8835.1387  8835.1387  0.0001 - |Sample:9.11|  |  02:01mins
EPOCH[13/101] loss 8741.5110  8741.5110  0.0001 - |Sample:8.75|  |  02:00mins
EPOCH[14/101] loss 8417.1211  8417.1211  0.0001 - |Sample:8.88|  |  02:00mins
EPOCH[15/101] loss 8273.3761  8273.3761  0.0001 - |Sample:8.71|  |  02:00mins
EPOCH[16/101] loss 7919.9802  7919.9802  0.0001 - |Sample:8.95|  |  02:00mins
EPOCH[17/101] loss 7955.3875  7955.3875  0.0001 - |Sample:8.75|  |  02:00mins
EPOCH[18/101] loss 7719.8627  7719.8627  0.0001 - |Sample:8.98|  |  02:00mins
EPOCH[19/101] loss 7506.1031  7506.1031  0.0001 - |Sample:9.13|  |  02:01mins
